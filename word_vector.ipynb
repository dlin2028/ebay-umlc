{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88b9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import multiprocessing\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4f3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_titles = pd.read_csv('./dataset/Listing_Titles.tsv', sep='\\t', on_bad_lines='skip', quoting=csv.QUOTE_NONE, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1295c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_titles = pd.read_csv('./dataset/Train_Tagged_Titles.tsv', sep='\\t', on_bad_lines='skip', quoting=csv.QUOTE_NONE, encoding='utf8')\n",
    "\n",
    "valid_tags = ['Accents', 'Brand', 'Character', 'Character Family', 'Closure', 'Color', 'Country/Region of Manufacture', 'Department', 'Fabric Type', 'Features', 'Handle Drop', 'Handle Style', 'Handle/Strap Material', 'Hardware Material', 'Lining Material', 'MPN', 'Material', 'Measurement, dimension', 'Model', 'Occasion', 'Pattern', 'Pocket Type', 'Product Line', 'Season', 'Size', 'Strap Drop', 'Style', 'Theme', 'Trim Material', 'Type']\n",
    "\n",
    "tokens = tagged_titles.groupby('Record Number')['Token'].apply(list).to_dict()\n",
    "tags = tagged_titles.groupby('Record Number')['Tag'].apply(list).to_dict()\n",
    "texts = tagged_titles.groupby('Record Number')['Title'].apply(list).to_dict()\n",
    "\n",
    "tokens = tagged_titles.groupby('Record Number')['Token'].apply(list).to_dict()\n",
    "tags = tagged_titles.groupby('Record Number')['Tag'].apply(list).to_dict()\n",
    "raw_tokenized_data = [[(tokens[i][tiddie], tags[i][tiddie]) for tiddie in range(0, len(tags[i]))] for i in range(1, len(tags) + 1)]\n",
    "\n",
    "#Append NaN token to previous value\n",
    "#ex. append \"Vuitton\" to \"Louis\" in \"Louis Vuitton\"\n",
    "for i in range(0, len(raw_tokenized_data)):\n",
    "    for j in reversed(range(1, len(raw_tokenized_data[i]))):\n",
    "        if (raw_tokenized_data[i][j][1] != raw_tokenized_data[i][j][1]): #python nan moment\n",
    "            raw_tokenized_data[i][j - 1] = (raw_tokenized_data[i][j - 1][0] + \" \" + raw_tokenized_data[i][j][0], raw_tokenized_data[i][j - 1][1])\n",
    "\n",
    "trimmed_tokenized_data = [[i for i in item if not i[1] != i[1]] for item in raw_tokenized_data]\n",
    "\n",
    "trimmed_tokenized_data\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for i in range(0, len(trimmed_tokenized_data)):\n",
    "    name = []\n",
    "    for j in range(0, len(trimmed_tokenized_data[i])):\n",
    "        name.append(trimmed_tokenized_data[i][j][0])\n",
    "    sentences.append(name)\n",
    "sentences = sentences[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064390dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordvecs(corpus, model_name):\n",
    "    from gensim.models.word2vec import Word2Vec\n",
    "    from gensim.models.phrases import Phrases, Phraser\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    print (len(corpus))\n",
    "    \n",
    "\n",
    "    phrases = Phrases(corpus, min_count=30, progress_per=10000)\n",
    "    print (\"Made Phrases\")\n",
    "    \n",
    "    bigram = Phraser(phrases)\n",
    "    print (\"Made Bigrams\")\n",
    "    \n",
    "    sentences = phrases[corpus]\n",
    "    print (\"Found sentences\")\n",
    "    word_freq = defaultdict(int)\n",
    "\n",
    "    for sent in sentences:\n",
    "        for i in sent:\n",
    "            word_freq[i]+=1\n",
    "\n",
    "    print (len(word_freq))\n",
    "    \n",
    "    print (\"Training model now...\")\n",
    "    w2v_model = Word2Vec(min_count=2,\n",
    "                        window=2,\n",
    "                        sample=6e-5,\n",
    "                        alpha=0.03,\n",
    "                        min_alpha=0.0007,\n",
    "                        negative=20)\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "    os.makedirs(\"./trainset\", exist_ok=True)\n",
    "    w2v_model.wv.save_word2vec_format(f\"trainset/{model_name}.txt\")\n",
    "    print(w2v_model.wv.most_similar('LOUIS VUITTON'))\n",
    "create_wordvecs(sentences, \"word_vecs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('poopy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "adf12df7b235022e4c7536daceb7bedbd14b85006e9114754938519bb40d111a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
