{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88b9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import multiprocessing\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4f3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_titles = pd.read_csv('./dataset/Train_Tagged_Titles.tsv', sep='\\t', on_bad_lines='skip', quoting=csv.QUOTE_NONE, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da76d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['Accents', 'Brand', 'Character', 'Character Family', 'Closure', 'Color', 'Country/Region of Manufacture', 'Department', 'Fabric Type', 'Features', 'Handle Drop', 'Handle Style', 'Handle/Strap Material', 'Hardware Material', 'Lining Material', 'MPN', 'Material', 'Measurement, Dimension', 'Model', 'Occasion', 'Pattern', 'Pocket Type', 'Product Line', 'Season', 'Size', 'Strap Drop', 'Style', 'Theme', 'Trim Material', 'Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1295c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiddies = tagged_titles.groupby('Record Number')['Token'].apply(list).to_dict()\n",
    "ass = tagged_titles.groupby('Record Number')['Tag'].apply(list).to_dict()\n",
    "\n",
    "kimk = [[(tiddies[i][tiddie], ass[i][tiddie]) for tiddie in range(0, len(ass[i]))] for i in range(1, len(ass) + 1)]\n",
    "\n",
    "for i in range(0, len(kimk)):\n",
    "    for j in reversed(range(1, len(kimk[i]))):\n",
    "        if(kimk[i][j][1] != kimk[i][j][1]): #python nan moment\n",
    "            kimk[i][j - 1] = (kimk[i][j - 1][0] + \" \" + kimk[i][j][0], kimk[i][j - 1][1])\n",
    "\n",
    "delphine = [[i for i in item if not i[1] != i[1]] for item in kimk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce5a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[delphine[i][j][0] for j in range(len(delphine[i]))] for i in range(len(delphine))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "064390dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "Made Phrases\n",
      "Made Bigrams\n",
      "Found sentences\n",
      "9505\n",
      "Training model now...\n"
     ]
    }
   ],
   "source": [
    "def create_wordvecs(corpus, model_name):\n",
    "    from gensim.models.word2vec import Word2Vec\n",
    "    from gensim.models.phrases import Phrases, Phraser\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    print (len(corpus))\n",
    "    \n",
    "\n",
    "    phrases = Phrases(corpus, min_count=30, progress_per=10000)\n",
    "    print (\"Made Phrases\")\n",
    "    \n",
    "    bigram = Phraser(phrases)\n",
    "    print (\"Made Bigrams\")\n",
    "    \n",
    "    sentences = phrases[corpus]\n",
    "    print (\"Found sentences\")\n",
    "    word_freq = defaultdict(int)\n",
    "\n",
    "    for sent in sentences:\n",
    "        for i in sent:\n",
    "            word_freq[i]+=1\n",
    "\n",
    "    print (len(word_freq))\n",
    "    \n",
    "    print (\"Training model now...\")\n",
    "    w2v_model = Word2Vec(min_count=1,\n",
    "                        window=2,\n",
    "                        sample=6e-5,\n",
    "                        alpha=0.03,\n",
    "                        min_alpha=0.0007,\n",
    "                        negative=20)\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "    os.makedirs(\"./trainset\", exist_ok=True)\n",
    "    w2v_model.wv.save_word2vec_format(f\"trainset/{model_name}.txt\")\n",
    "create_wordvecs(sentences, \"word_vecs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094240c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('poopy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f52ab0dcc20aaef27cce08a77f09e222b8b3949b76637bac784c92d7f6a2f51c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
